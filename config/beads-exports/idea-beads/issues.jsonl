{"id":"idea-00l","title":"Facebook Marketplace monitor — local area product search via ai-marketplace-monitor","description":"## Summary\n\nResearch on crawling Facebook Marketplace for specific devices/products in a local area. Best option is BoPeng/ai-marketplace-monitor.\n\n## Top Pick: BoPeng/ai-marketplace-monitor\n\n- **URL:** https://github.com/BoPeng/ai-marketplace-monitor\n- **Stars:** 136 | **Last active:** Feb 2026\n- **Install:** `pip install ai-marketplace-monitor` + `playwright install`\n- **Config:** TOML file at `~/.ai-marketplace-monitor/config.toml`\n- **Features:**\n  - Search by product name + city/region with configurable radius\n  - Boolean keyword filtering: `('Go Pro' OR gopro) AND (11 OR 12 OR 13)`\n  - Min/max price, exclusions, seller location filtering\n  - Continuous monitoring mode — watches for new listings\n  - Notifications: Telegram, PushBullet, PushOver, Ntfy, HTML email\n  - Optional AI deal scoring (OpenAI, DeepSeek, or self-hosted Ollama)\n  - Well-engineered: tests, CI, docs on ReadTheDocs\n\n## Other Options Evaluated\n\n| Repo | Approach | Last Updated | Verdict |\n|---|---|---|---|\n| JustSxm/Deals-Scraper | Browser session | Apr 2023 | Stale, multi-platform (eBay, Kijiji) |\n| passivebot/facebook-marketplace-scraper | Playwright + FastAPI + Streamlit | Apr 2024 | **Archived**, was most popular (368 stars) |\n| kyleronayne/marketplace-api | Direct GraphQL API (no browser) | Apr 2022 | Elegant but likely broken, FB changes API often |\n| gmoz22/facebook-marketplace-nationwide | Opens browser tabs per city | Mar 2025 | Not a real scraper, just URL construction |\n\n## Legal Notes\n\n- Facebook ToS prohibits automated scraping\n- California court ruled FB terms don't prohibit scraping of publicly available data by logged-out users\n- For personal use monitoring a few products locally, main risk is account suspension not legal action\n- Most tools require login with your own Facebook account (the account at risk)\n- All repos include \"use at your own risk\" disclaimers\n\n## Sources\n\n- https://github.com/BoPeng/ai-marketplace-monitor\n- https://github.com/JustSxm/Deals-Scraper\n- https://github.com/passivebot/facebook-marketplace-scraper\n- https://github.com/kyleronayne/marketplace-api\n- https://github.com/gmoz22/facebook-marketplace-nationwide","status":"open","priority":2,"issue_type":"task","owner":"trillium@trilliumsmith.com","created_at":"2026-02-19T12:34:17.133674245-08:00","created_by":"Trillium Smith","updated_at":"2026-02-19T12:34:17.133674245-08:00","labels":["automation","marketplace","monitoring"]}
{"id":"idea-492","title":"Database connection timeout in production","description":"Users experiencing intermittent 500 errors due to database timeouts","status":"open","priority":1,"issue_type":"bug","owner":"trillium@trilliumsmith.com","created_at":"2026-02-14T08:46:42.087530209-08:00","created_by":"Trillium Smith","updated_at":"2026-02-14T08:46:42.087530209-08:00","labels":["backend","urgent"]}
{"id":"idea-51v","title":"Talon command discovery engine — crawl community .talon repos, parse voice command bindings, index alternatives across forks. Inspired by stolen-sugar (archived). Could be a new page on awesome-talon site or standalone project. See https://github.com/stolen-sugar/stolen-sugar","description":"## Talon Command Discovery Engine\n\nResearch complete. Implementation tracked as epic awesome-talon-81y in repo-local beads (bd).\n\nSee bd show awesome-talon-81y and bd children awesome-talon-81y for the full 10-step breakdown.","status":"open","priority":2,"issue_type":"epic","owner":"trillium@trilliumsmith.com","created_at":"2026-02-17T12:18:46.229585856-08:00","created_by":"Trillium Smith","updated_at":"2026-02-17T13:25:29.027296629-08:00"}
{"id":"idea-51v.1","title":"Step 1: Python crawler — fetch .talon file trees from GitHub API","description":"## What\nWrite a Python script (`scripts/crawl_talon_files.py`) that:\n1. Reads `repos_full.json` for the list of repos to crawl\n2. For each repo, calls GitHub Trees API (`GET /repos/{owner}/{repo}/git/trees/{branch}?recursive=1`) to list all files\n3. Filters for `.talon` files\n4. Fetches file content via Blobs API (`GET /repos/{owner}/{repo}/git/blobs/{sha}`)\n5. Caches fetched content by blob SHA in a local cache dir (content-addressable)\n6. Supports incremental mode: skip repos not pushed since last run (compare `pushed_at` to last crawl timestamp)\n7. Outputs raw `.talon` content to `talon_files_raw.json` — array of `{repo, path, sha, content, context_header}`\n\n## Verify\n- [ ] Script runs without errors against live GitHub API\n- [ ] Produces `talon_files_raw.json` with entries from at least 50 repos\n- [ ] Incremental mode skips unchanged repos on second run\n- [ ] Respects GitHub API rate limits (5,000/hr)\n- [ ] Cache directory stores files by blob SHA, reused across runs","status":"tombstone","priority":2,"issue_type":"task","owner":"trillium@trilliumsmith.com","created_at":"2026-02-17T13:19:18.694369782-08:00","created_by":"Trillium Smith","updated_at":"2026-02-17T13:24:26.847605193-08:00","deleted_at":"2026-02-17T13:24:26.847605193-08:00","deleted_by":"Trillium Smith","delete_reason":"delete","original_type":"task"}
{"id":"idea-51v.10","title":"Step 10: Seed data — run initial crawl and commit commands_index.json","description":"## What\n1. Run the full pipeline locally to generate the first commands_index.json\n2. Validate the output: check file size, command count, parse success rate\n3. Commit commands_index.json to website/data/ so the site builds without CI\n4. Document any issues found during the initial crawl (update epic if needed)\n5. Verify the website builds and /commands page renders with real data\n\n## Verify\n- [ ] commands_index.json exists in website/data/ and is committed\n- [ ] File size is reasonable (under 10MB)\n- [ ] next build succeeds with the seeded data\n- [ ] /commands page renders with real commands from the ecosystem\n- [ ] At least 50 repos contributed commands to the index\n- [ ] Stats numbers match expectations from the research (8-10K files, 100K+ commands)","status":"tombstone","priority":2,"issue_type":"task","owner":"trillium@trilliumsmith.com","created_at":"2026-02-17T13:21:51.006080137-08:00","created_by":"Trillium Smith","updated_at":"2026-02-17T13:25:16.366842946-08:00","deleted_at":"2026-02-17T13:25:16.366842946-08:00","deleted_by":"Trillium Smith","delete_reason":"delete","original_type":"task"}
{"id":"idea-51v.2","title":"Step 2: .talon file parser — extract voice commands","description":"## What\nWrite a Python module (scripts/parse_talon.py) that:\n1. Parses .talon file format: context header (above - separator) + command rules (below)\n2. Extracts each command as {spoken_rule, action_body, context}\n3. Handles rule syntax: alternatives (a|b), optionals [word], captures \u003cuser.text\u003e, lists {user.list}\n4. Normalizes context headers (e.g. os: mac, tag: user.cursorless, app: vscode)\n5. Start with regex parsing (handles ~95% of files)\n6. Gracefully skip unparseable files, log warnings\n\n## Verify\n- [ ] Correctly parses talonhub/community .talon files (218 files, ~2500 commands)\n- [ ] Unit tests cover: basic commands, multi-line actions, context headers, rule syntax variants\n- [ ] Parse success rate \u003e= 90% across full corpus\n- [ ] Unparseable files logged but do not crash the script","status":"tombstone","priority":2,"issue_type":"task","owner":"trillium@trilliumsmith.com","created_at":"2026-02-17T13:19:43.462035952-08:00","created_by":"Trillium Smith","updated_at":"2026-02-17T13:24:32.29508972-08:00","deleted_at":"2026-02-17T13:24:32.29508972-08:00","deleted_by":"Trillium Smith","delete_reason":"delete","original_type":"task"}
{"id":"idea-51v.3","title":"Step 3: Command indexer — group by action, find alternatives","description":"## What\nWrite a Python module (scripts/index_commands.py) that:\n1. Reads parsed commands from step 2\n2. Groups commands by normalized action body to find alternative spoken forms across repos\n3. Identifies the \"canonical\" form (from talonhub/community) vs alternatives in other repos\n4. Deduplicates commands copied verbatim from community (same blob SHA or identical content)\n5. Computes stats: total unique commands, repos with most custom commands, most-overridden commands\n6. Outputs commands_index.json structured for the website:\n   - Array of command groups: {action, canonical_rule, alternatives: [{rule, repo, context, path}], category}\n   - Summary stats object: {total_commands, total_repos_with_talon, total_files_parsed, generated_at}\n7. Outputs should be reasonably sized for client-side consumption (\u003c10MB, ideally \u003c5MB)\n\n## Verify\n- [ ] commands_index.json is valid JSON and loadable in Node.js\n- [ ] Contains grouped commands with alternatives from multiple repos\n- [ ] Canonical vs alternative distinction works (community commands marked)\n- [ ] Stats object has accurate counts\n- [ ] File size is under 10MB","status":"tombstone","priority":2,"issue_type":"task","owner":"trillium@trilliumsmith.com","created_at":"2026-02-17T13:20:03.152283822-08:00","created_by":"Trillium Smith","updated_at":"2026-02-17T13:24:38.039776174-08:00","deleted_at":"2026-02-17T13:24:38.039776174-08:00","deleted_by":"Trillium Smith","delete_reason":"delete","original_type":"task"}
{"id":"idea-51v.4","title":"Step 4: Pipeline orchestrator — single entry point for CI","description":"## What\nWrite a main script (scripts/build_commands_index.py) that:\n1. Orchestrates steps 1-3 in sequence: crawl -\u003e parse -\u003e index\n2. Accepts CLI flags: --full (ignore cache, recrawl everything), --repos-file (path to repos_full.json)\n3. Writes final commands_index.json to website/data/commands_index.json\n4. Prints summary to stdout (total repos crawled, files parsed, commands indexed, errors)\n5. Exits with nonzero code on critical failure (e.g. no GitHub token, API down)\n6. Handles GITHUB_TOKEN from environment (same pattern as existing enrich.py)\n7. Includes requirements.txt or uses only stdlib (match existing script conventions)\n\n## Verify\n- [ ] Running the script end-to-end produces website/data/commands_index.json\n- [ ] Summary output is printed to stdout\n- [ ] --full flag forces complete recrawl\n- [ ] Script fails gracefully with clear error if GITHUB_TOKEN is missing\n- [ ] Exit code is 0 on success, nonzero on failure","status":"tombstone","priority":2,"issue_type":"task","owner":"trillium@trilliumsmith.com","created_at":"2026-02-17T13:20:19.257047968-08:00","created_by":"Trillium Smith","updated_at":"2026-02-17T13:24:43.587545162-08:00","deleted_at":"2026-02-17T13:24:43.587545162-08:00","deleted_by":"Trillium Smith","delete_reason":"delete","original_type":"task"}
{"id":"idea-51v.5","title":"Step 5: GitHub Action — weekly CI for command index","description":"## What\nAdd command indexing to the CI pipeline:\n1. Either extend deploy-website.yml or create a new workflow (crawl-commands.yml)\n2. Runs weekly (same schedule as deploy, Monday 6am UTC) + manual trigger\n3. Steps: checkout -\u003e setup Python -\u003e run build_commands_index.py -\u003e copy output to website/data/\n4. If extending deploy-website.yml: add steps before the Next.js build\n5. GITHUB_TOKEN provided via secrets (same as existing enrich.py)\n6. Cache the blob SHA cache directory between CI runs for incremental crawling\n\n## Verify\n- [ ] Workflow runs successfully in GitHub Actions (manual trigger test)\n- [ ] commands_index.json is available in website/data/ before Next.js build\n- [ ] Cache persists between workflow runs (incremental crawling works)\n- [ ] Workflow completes within GitHub Actions time limits\n- [ ] deploy-website.yml still deploys successfully with the new step","status":"tombstone","priority":2,"issue_type":"task","owner":"trillium@trilliumsmith.com","created_at":"2026-02-17T13:20:35.038233178-08:00","created_by":"Trillium Smith","updated_at":"2026-02-17T13:24:49.095589268-08:00","deleted_at":"2026-02-17T13:24:49.095589268-08:00","deleted_by":"Trillium Smith","delete_reason":"delete","original_type":"task"}
{"id":"idea-51v.6","title":"Step 6: Data loader — load-commands.ts library module","description":"## What\nCreate website/src/lib/load-commands.ts following existing patterns (load-repos.ts, load-resource-dates.ts):\n1. Reads website/data/commands_index.json at build time\n2. Exports TypeScript types: CommandGroup, CommandAlternative, CommandsIndex, CommandStats\n3. Exports loadCommands(): CommandsIndex function\n4. Graceful fallback: returns empty data if file missing (matches load-resource-dates.ts pattern)\n5. Types should cover: action, canonical spoken rule, alternatives with repo/context/path, stats\n\n## Verify\n- [ ] Types are well-defined and exported\n- [ ] loadCommands() returns typed data from commands_index.json\n- [ ] Returns empty/default data when file is missing (no build crash)\n- [ ] Can be imported and used in a Next.js server component","status":"tombstone","priority":2,"issue_type":"task","owner":"trillium@trilliumsmith.com","created_at":"2026-02-17T13:20:51.154849845-08:00","created_by":"Trillium Smith","updated_at":"2026-02-17T13:24:54.454947977-08:00","deleted_at":"2026-02-17T13:24:54.454947977-08:00","deleted_by":"Trillium Smith","delete_reason":"delete","original_type":"task"}
{"id":"idea-51v.7","title":"Step 7: /commands page — server component shell","description":"## What\nCreate website/src/app/commands/page.tsx:\n1. Server component that loads commands index via loadCommands()\n2. Converts data for client serialization (same Map-\u003eObject pattern as list/page.tsx)\n3. Passes data to a CommandsExplorer client component\n4. Includes page metadata (title, description) for SEO\n5. Shows stats banner: total commands, repos with .talon files, files parsed, last updated\n6. Graceful empty state if commands_index.json is missing or empty\n\n## Verify\n- [ ] Page renders at /commands without errors\n- [ ] Stats banner shows accurate numbers from the index\n- [ ] Empty state renders cleanly when no data is available\n- [ ] Page metadata is correct\n- [ ] next build succeeds with the new page","status":"tombstone","priority":2,"issue_type":"task","owner":"trillium@trilliumsmith.com","created_at":"2026-02-17T13:21:06.345524216-08:00","created_by":"Trillium Smith","updated_at":"2026-02-17T13:24:59.786474164-08:00","deleted_at":"2026-02-17T13:24:59.786474164-08:00","deleted_by":"Trillium Smith","delete_reason":"delete","original_type":"task"}
{"id":"idea-51v.8","title":"Step 8: CommandsExplorer — client component with search and filtering","description":"## What\nCreate website/src/components/CommandsExplorer.tsx (client component):\n1. Search input: filter commands by spoken rule or action body (real-time, like ListSearch)\n2. Filter by context: dropdown/chips for common contexts (mac, linux, windows, vscode, browser, etc.)\n3. Filter by repo: show commands from specific repos\n4. Sort options: alphabetical by spoken rule, most alternatives, canonical first\n5. Display each command group as a card:\n   - Canonical spoken rule (highlighted)\n   - Action body (code-formatted)\n   - Expandable list of alternatives with repo name + context\n   - Count badge showing number of alternative forms\n6. Pagination or virtual scrolling for large result sets (100k+ commands)\n7. Follow existing component styling patterns (Tailwind, dark mode support)\n\n## Verify\n- [ ] Search filters commands in real-time without lag\n- [ ] Context and repo filters work correctly\n- [ ] Sort options reorder results as expected\n- [ ] Command cards display canonical vs alternatives clearly\n- [ ] Dark mode renders correctly\n- [ ] Performance is acceptable with full dataset (no jank on initial load)\n- [ ] Pagination/virtualization handles large result sets","status":"tombstone","priority":2,"issue_type":"task","owner":"trillium@trilliumsmith.com","created_at":"2026-02-17T13:21:23.43978557-08:00","created_by":"Trillium Smith","updated_at":"2026-02-17T13:25:05.419849788-08:00","deleted_at":"2026-02-17T13:25:05.419849788-08:00","deleted_by":"Trillium Smith","delete_reason":"delete","original_type":"task"}
{"id":"idea-51v.9","title":"Step 9: Navigation — add Commands link to site nav","description":"## What\n1. Add \"Commands\" link to the site navigation/header alongside existing pages\n2. Add a Commands section or link to the home page (similar to how Ecosystem and Curated List are linked)\n3. Update home page stats if relevant (e.g. add a \"Voice commands indexed\" stat)\n\n## Verify\n- [ ] Commands link appears in site navigation\n- [ ] Link navigates to /commands correctly\n- [ ] Active state works when on /commands page\n- [ ] Home page references the commands feature\n- [ ] All existing navigation still works","status":"tombstone","priority":2,"issue_type":"task","owner":"trillium@trilliumsmith.com","created_at":"2026-02-17T13:21:36.365991948-08:00","created_by":"Trillium Smith","updated_at":"2026-02-17T13:25:10.937440748-08:00","deleted_at":"2026-02-17T13:25:10.937440748-08:00","deleted_by":"Trillium Smith","delete_reason":"delete","original_type":"task"}
{"id":"idea-5gg","title":"Design API endpoints","status":"open","priority":2,"issue_type":"task","owner":"trillium@trilliumsmith.com","created_at":"2026-02-14T08:46:41.685825847-08:00","created_by":"Trillium Smith","updated_at":"2026-02-14T08:46:41.685825847-08:00","dependencies":[{"issue_id":"idea-5gg","depends_on_id":"idea-vxu","type":"blocks","created_at":"2026-02-14T08:46:58.100787775-08:00","created_by":"Trillium Smith"}]}
{"id":"idea-66v","title":"Local TTS system for AI agent speech — Piper HTTP server + bash speak wrapper + optional MCP tool for reading summaries aloud","description":"Research completed on local TTS for AI agents (Claude Code, etc) to speak summaries aloud. Recommended architecture: (1) Piper TTS as the engine — fast ONNX inference, ~60-100MB models, runs on Raspberry Pi, ideal for resource-constrained systems. (2) Piper built-in HTTP server on localhost:5000 keeps model loaded persistently. (3) Bash 'speak' wrapper script that POSTs to the HTTP server and plays audio. (4) Optional MCP server (piper-tts-mcp) for direct Claude Code integration. Best voices: en_US-lessac-high, en_US-ryan-high. Streaming supported at sentence boundaries. See full research notes in Claude Code conversation.","status":"open","priority":2,"issue_type":"task","owner":"trillium@trilliumsmith.com","created_at":"2026-02-17T17:45:52.574273472-08:00","created_by":"Trillium Smith","updated_at":"2026-02-17T17:46:07.089722014-08:00"}
{"id":"idea-7g7","title":"Dictation coach: auto-detect misrecognition patterns and suggest words_to_replace corrections","description":"## Research Findings: Dictation Coach System Design\n\n### 1. Available Talon APIs for Speech/Phrase Tracking\n\nThe Talon speech_system module provides three event hooks that all existing plugins use:\n\n- **speech_system.register(\"pre:phrase\", callback)** -- Called BEFORE a phrase is executed. The callback receives a Phrase dict with phrase[\"phrase\"] (list of recognized words) and phrase[\"parsed\"] (parsed rule tree). Used by: cancel.py, macro.py, subtitles/on_phrase.py.\n\n- **speech_system.register(\"phrase\", callback)** -- Called during phrase processing. Used by: command_history.py, subtitles on_phrase.py.\n\n- **speech_system.register(\"post:phrase\", callback)** -- Called AFTER a phrase has been fully executed. Used by: repeater.py, command_logger.py, listening_timeout.py, deprecations.py. This is the richest hook because actions.core.last_command() and actions.core.last_phrase() are available.\n\nKey APIs available in post:phrase handlers:\n- actions.core.last_command() returns (command, capture) tuple\n- actions.core.last_phrase() returns the raw phrase words as spoken\n- actions.core.repeat_phrase(n) replays the last phrase\n\n### 2. Existing Infrastructure Already in Place\n\n**command_logger.py** (trillium/plugin/repeater/command_logger.py):\nAlready logging every command to ~/.talon/recordings/commands/ as JSON (10,495 files). Each has: command trigger, spoken phrase words, app context, timestamp. Goldmine for offline analysis.\n\n**phrase_history.py** (core/text/phrase_history.py):\nIn-memory list of last 40 dictated phrases. Actions: get_last_phrase(), clear_last_phrase(), add_phrase_to_history(text).\n\n**vocabulary.py** (core/vocabulary/vocabulary.py):\nPhraseReplacer handles multi-word replacement. words_to_replace.csv loaded via track_csv_list. append_to_csv() can programmatically add entries.\n\n**Existing correction commands:**\n- \"nope\" / \"undo that\" -\u003e edit.undo()\n- \"nope that\" / \"scratch that\" -\u003e user.clear_last_phrase() (backspace)\n- \"copy to replacements as \u003cphrase\u003e\" -\u003e manual add to words_to_replace.csv\n\n### 3. Proposed Architecture\n\n#### Phase 1: Correction Logging (Passive)\n\nHook into post:phrase to detect correction patterns. State machine:\n\nIDLE -\u003e dictation event -\u003e WATCHING\nWATCHING -\u003e correction event (nope/scratch) -\u003e EXPECTING_REPLACEMENT\nEXPECTING_REPLACEMENT -\u003e new dictation within 30s -\u003e LOG CORRECTION PAIR\nAny state -\u003e timeout or irrelevant command -\u003e IDLE\n\nData per correction: timestamp, original_phrase, original_text, corrected_phrase, corrected_text, correction_method, time_delta, app_context\n\n#### Phase 2: Suggestion Engine\n\nTally correction pairs. After N occurrences (default 3), show overlay: \"Detected: 'contact seven' -\u003e 'context seven' (3x). Say 'coach accept' to add.\" Calls append_to_csv to write to words_to_replace.csv.\n\n### 4. Detection Algorithm\n\nDictation triggers to watch: \u003cuser.raw_prose\u003e, phrase \u003cuser.text\u003e, {user.prose_formatter} \u003cuser.prose\u003e, \u003cuser.format_code\u003e+\nCorrection triggers: nope, undo that, nope that, scratch that\n\nEdge cases: multiple undos, partial corrections, format corrections (nope that was snake -- NOT misrecognitions), context switches.\n\n### 5. Data Storage\n\n~/.talon/dictation_coach/corrections.jsonl -- append-only correction pairs\n~/.talon/dictation_coach/correction_tallies.json -- aggregated counts\n~/.talon/dictation_coach/suggestions_state.json -- accepted/rejected state\n\n### 6. Voice Commands\n\ncoach list -- review pending suggestions\ncoach accept [N] -- accept suggestion N, add to words_to_replace.csv\ncoach reject [N] -- dismiss suggestion\ncoach wrong -- manually mark last phrase as wrong (simplest approach)\ncoach stats -- show correction statistics\ncoach threshold N -- set how many occurrences before suggesting\ncoach pause/resume -- toggle the system\n\n### 7. Feasibility\n\nFEASIBLE NOW: All speech_system hooks proven. post:phrase gives last_command/last_phrase. phrase_history tracks inserted text. append_to_csv ready. Canvas overlay proven.\n\nCHALLENGES: Detecting actual deleted text is imprecise (nope triggers edit.undo but we don't know what was undone). Timing windows are heuristic. Multi-word replacements work but dictate.word_map only handles single words.\n\nWOULD NEED CORE CHANGES: N-best list from speech engine, confidence scores per word, formal correction events, text-deleted callbacks.\n\n### 8. Existing Community Work\n\n- AndreasArvidsson/andreas-talon: Smart homophones (remembers homophone choices). Similar but limited to homophones.\n- No existing community plugin does auto-correction-detection for arbitrary misrecognitions.\n- The command_logger in this repo could be analyzed retroactively.\n\n### 9. Complexity Estimate\n\nPhase 1 (Passive Logging): 1-2 hours, ~150 lines\nPhase 2 (Suggestion Engine + Voice Commands): 3-4 hours, ~300 lines\nPhase 3 (Offline Analysis of 10K+ existing logs): 2-3 hours\nPhase 4 (Polish/Config/Stats): 2-3 hours\nTotal: ~8-12 hours\n\n### 10. Recommended Starting Point\n\nStart with \"coach wrong\" manual command + passive logging. User flow:\n1. Says \"contact seven\" (text appears)\n2. Says \"coach wrong\" (system records phrase, enters EXPECTING state)\n3. Says \"context seven\" (system logs correction pair)\n4. After 3 occurrences, suggests adding to words_to_replace.csv\n\nThis avoids auto-detection complexity while solving the core problem. Auto-detection from undo/nope patterns layered on later.\n\n### Key Files\n- core/vocabulary/vocabulary.py -- PhraseReplacer, words_to_replace, append_to_csv\n- core/text/phrase_history.py -- last 40 phrases in memory\n- core/text/text.talon -- nope that / scratch that commands\n- core/text/text_and_dictation.py -- dictation formatting\n- plugin/subtitles/on_phrase.py -- speech_system.register(\"phrase\") example\n- plugin/command_history/command_history.py -- phrase history tracking\n- plugin/cancel/cancel.py -- pre:phrase example\n- trillium/plugin/repeater/command_logger.py -- post:phrase + JSON logging pattern\n- trillium/plugin/repeater/repeater.py -- post:phrase + actions.core.last_command()\n- core/user_settings.py -- append_to_csv, track_csv_list\n- settings/words_to_replace.csv -- 23 current entries including context7, close, vercel, tailwind","status":"open","priority":2,"issue_type":"task","owner":"trillium@trilliumsmith.com","created_at":"2026-02-17T12:41:09.494324376-08:00","created_by":"Trillium Smith","updated_at":"2026-02-17T12:43:42.856618999-08:00"}
{"id":"idea-anp","title":"Deploy to staging","status":"open","priority":2,"issue_type":"task","owner":"trillium@trilliumsmith.com","created_at":"2026-02-14T08:46:53.360603252-08:00","created_by":"Trillium Smith","updated_at":"2026-02-14T08:46:53.360603252-08:00","dependencies":[{"issue_id":"idea-anp","depends_on_id":"idea-ov6","type":"blocks","created_at":"2026-02-14T08:47:07.662166689-08:00","created_by":"Trillium Smith"}]}
{"id":"idea-cw4","title":"Refactor legacy payment processing code","description":"Clean up technical debt in payment module","status":"open","priority":2,"issue_type":"task","owner":"trillium@trilliumsmith.com","created_at":"2026-02-14T08:46:50.0322394-08:00","created_by":"Trillium Smith","updated_at":"2026-02-14T08:46:50.0322394-08:00","labels":["backend","tech-debt"]}
{"id":"idea-dm9","title":"Implement user authentication API","description":"Create REST API endpoints for user login and registration","status":"open","priority":1,"issue_type":"task","owner":"trillium@trilliumsmith.com","created_at":"2026-02-14T08:46:37.785507054-08:00","created_by":"Trillium Smith","updated_at":"2026-02-14T08:46:37.785507054-08:00","labels":["backend","urgent"]}
{"id":"idea-fo1","title":"Implement user authentication system","description":"Add OAuth2 and JWT-based authentication with support for multiple providers including Google, GitHub, and email/password","status":"open","priority":0,"issue_type":"feature","owner":"trillium@trilliumsmith.com","created_at":"2026-02-14T08:46:55.020030324-08:00","created_by":"Trillium Smith","updated_at":"2026-02-14T08:47:13.330518849-08:00","labels":["api","authentication","backend","critical","oauth2","security"],"comments":[{"id":1,"issue_id":"idea-fo1","author":"Trillium Smith","text":"Initial analysis: We should start with OAuth2 implementation for Google and GitHub providers","created_at":"2026-02-14T16:47:00Z"},{"id":2,"issue_id":"idea-fo1","author":"Trillium Smith","text":"Security consideration: Ensure token refresh mechanism is properly implemented to handle expired tokens","created_at":"2026-02-14T16:47:06Z"}]}
{"id":"idea-ov6","title":"Write API tests","status":"open","priority":2,"issue_type":"task","owner":"trillium@trilliumsmith.com","created_at":"2026-02-14T08:46:49.977560119-08:00","created_by":"Trillium Smith","updated_at":"2026-02-14T08:46:49.977560119-08:00","dependencies":[{"issue_id":"idea-ov6","depends_on_id":"idea-5gg","type":"blocks","created_at":"2026-02-14T08:47:02.407133596-08:00","created_by":"Trillium Smith"}]}
{"id":"idea-pnf","title":"Find My Repo — personalized command comparison on /commands page","description":"Follow-up to epic awesome-talon-81y (Talon Command Discovery Engine).\n\n## Concept\nAdd a \"Find my repo\" input to the /commands page where a user types their GitHub repo slug (e.g. fidgetingbits/fidget) and the page highlights:\n- Commands from YOUR repo (what you have)\n- Commands you are MISSING compared to talonhub/community (gaps)\n- Commands that are UNIQUE to your repo (your innovations)\n- Alternative spoken forms you use vs the canonical community form\n\n## Why this works without a backend\nThe command index already contains all commands from all 302 tracked repos. This is purely client-side filtering — no crawling on demand, no user accounts, no backend state. The user just picks their repo from the existing index.\n\n## Limitation\nOnly works for repos already in the tracked set (repos_full.json). If someone has a private or untracked repo, they would not see their data. Could add a note: \"Dont see your repo? Submit a PR to add it to the list.\"\n\n## Depends on\n- awesome-talon-81y (command discovery engine) being complete\n- The summary JSON already has repoSlug per command, so filtering is trivial\n\n## UX sketch\n- Small input or typeahead at top of /commands page: \"Find your repo...\"\n- Once selected, toggle between: \"All commands\", \"My commands\", \"Missing from my config\", \"Unique to me\"\n- Could persist the selected repo in localStorage for return visits","status":"open","priority":2,"issue_type":"feature","owner":"trillium@trilliumsmith.com","created_at":"2026-02-17T13:54:31.937153703-08:00","created_by":"Trillium Smith","updated_at":"2026-02-17T13:54:31.937153703-08:00"}
{"id":"idea-qgn","title":"Add export functionality for user reports","description":"Allow users to export their data as CSV or PDF","status":"open","priority":3,"issue_type":"feature","owner":"trillium@trilliumsmith.com","created_at":"2026-02-14T08:46:55.698782117-08:00","created_by":"Trillium Smith","updated_at":"2026-02-14T08:46:55.698782117-08:00","labels":["frontend"]}
{"id":"idea-sv1","title":"Add user login functionality","description":"Implement login system with OAuth support","status":"closed","priority":2,"issue_type":"feature","owner":"trillium@trilliumsmith.com","created_at":"2026-02-14T08:47:24.013101228-08:00","created_by":"Trillium Smith","updated_at":"2026-02-14T08:48:10.448300485-08:00","closed_at":"2026-02-14T08:48:10.448300485-08:00","close_reason":"Duplicate of idea-fo1","labels":["authentication","backend"],"comments":[{"id":3,"issue_id":"idea-sv1","author":"Trillium Smith","text":"This issue is a duplicate of idea-fo1 (Implement user authentication system)","created_at":"2026-02-14T16:48:19Z"}]}
{"id":"idea-uql","title":"Record short demo video for recall README","description":"Record a ~10s screencast showing recall voice commands (assign, switch, list, focus). Commit MP4 to repo images/ dir and embed in README. ffmpeg is installed and ready.","status":"open","priority":3,"issue_type":"task","owner":"trillium@trilliumsmith.com","created_at":"2026-02-18T21:35:38.11592062-08:00","created_by":"Trillium Smith","updated_at":"2026-02-18T21:35:38.11592062-08:00"}
{"id":"idea-vxu","title":"Implement database schema","status":"open","priority":2,"issue_type":"task","owner":"trillium@trilliumsmith.com","created_at":"2026-02-14T08:46:45.420300252-08:00","created_by":"Trillium Smith","updated_at":"2026-02-14T08:46:45.420300252-08:00"}
{"id":"idea-w9z","title":"Add dark mode to user interface","description":"Implement dark theme toggle for better user experience","status":"open","priority":2,"issue_type":"feature","owner":"trillium@trilliumsmith.com","created_at":"2026-02-14T08:46:46.247460907-08:00","created_by":"Trillium Smith","updated_at":"2026-02-14T08:46:46.247460907-08:00","labels":["frontend"]}
{"id":"idea-xne","title":"Talon speech pipeline internals — VAD config, decoder opts, and tuning knobs","description":"## Summary\n\nDocumented the full Talon speech-to-command pipeline by exploring internals via the Talon REPL (`~/.talon/bin/repl`). This covers the 5-stage pipeline from microphone to action execution, with all tunable parameters.\n\n## Pipeline\n\n1. **Microphone → VAD** (Voice Activity Detection) — RNN-based, runs on raw 16kHz stereo audio\n2. **VAD → Encoder** — W2lOrtEncoder (ONNX Runtime Conformer model)\n3. **Encoder → Decoder** — Beam search with grammar-constrained decoding\n4. **Decoder → CFGLinker** — DFA-based command matching against .talon rules\n5. **Grammar → Action Execution** — Runs matched actions with key timing settings\n\n## Key Tunable: speech.timeout (VAD silence duration)\n\nThe main knob controlling \"how long Talon waits before executing a command\" is `speech.timeout` (default 0.3s). This is the silence duration the VAD waits after you stop talking before firing audio to the engine. Lower = faster but may cut off multi-word phrases. Higher = more reliable but sluggish.\n\nSet in settings.talon:\n```\nspeech.timeout = 0.2\n```\n\nOr dynamically:\n```python\nfrom talon import speech_system\nspeech_system.vad.set_timeout(0.2)\n```\n\n## Full VAD Config (C struct at speech_system.vad.config)\n\n| Field | Value | Purpose |\n|---|---|---|\n| timeout | 0.3s | Silence before processing |\n| rnn_threshold | 0.75 | Voice activity sensitivity (= speech.threshold) |\n| pre_time | 0.15s | Audio buffered before voice onset |\n| min_time | 0.025s | Minimum speech duration |\n| recover_time | 0.0s | Gap tolerance mid-speech |\n| sample_rate | 16000 | Hz |\n| channels | 2 | Stereo |\n\n## Decoder Beam Search Options (speech_system.engine.engine.decoder.opts)\n\n| Option | Value | Meaning |\n|---|---|---|\n| beamsize | 183 | Parallel hypotheses |\n| beamsizetoken | 25000 | Token-level beam width |\n| lmweight | 0.703 | Language model influence |\n| command_score | 0.5 | Bonus for matching a known command |\n| unkweight | -inf | Unknown words completely rejected |\n| wordscore | -0.277 | Slight penalty per word insertion |\n| viterbi_reject_threshold | 0.55 | |\n| viterbi_reject_window | 8 | |\n\n## Key Execution Timing Settings\n\n| Setting | Value | Purpose |\n|---|---|---|\n| key_wait | 1.0ms | Pause between modifier and key presses |\n| key_hold | 0.0ms | Time between key press and release |\n| insert_wait | 0.0ms | Pause between each character in insert() |\n| hotkey_wait | 0.0ms | Pause after hotkey combos |\n| paste_wait | 250ms | Wait before restoring clipboard |\n\n## Available Engines (4 loaded, 1 active)\n\n- **fast Conformer b108 (2021-09-15)** — ACTIVE (subtype: conformer)\n- Conformer D2 (2025-01-06) — disabled\n- Conformer D (2025-01-06) — disabled\n- Dragon — disabled\n\n## REPL Exploration Steps\n\nHere's how this was discovered, step by step:\n\n1. `from talon import settings; settings.list()` — listed all registered settings including speech.* and key_*\n2. `settings.get(\"speech.timeout\")` etc — read current values of all speech and key timing settings\n3. `from talon import speech_system` — accessed the speech system singleton\n4. `speech_system.vad` — found the VAD object (talon.vad.Vad)\n5. `speech_system.vad.config` — found the C struct (tl_vad_config) with timeout, rnn_threshold, pre_time, min_time, recover_time, mode, sample_rate, channels, debug\n6. `speech_system.engine` — found the EngineProxy wrapping W2lEngine\n7. `speech_system.engine.engine` — unwrapped to get the inner W2lEngine with encoder, decoder, cfg_linker\n8. `speech_system.engine.engine.decoder.opts` — found the C struct with beam search parameters\n9. `speech_system.engine.engine.cfg_linker` — found the CFGLinker (grammar DFA matcher)\n10. `speech_system.engine.engine.word_model` — found AlphaWordModel (constrains decoder to valid words)\n11. `speech_system.engines` — listed all 4 loaded engines and their enable status\n12. `speech_system.vad.set_timeout` / `set_threshold` — confirmed these methods exist for dynamic tuning\n\nAll exploration done via: `echo 'python code' | ~/.talon/bin/repl`","notes":"## Motivation: Dynamic Speech Timeout\n\nThe goal is to dynamically adjust `speech.timeout` (the silence duration before Talon processes a phrase) based on context. Rather than a single fixed value, the timeout could adapt — for example:\n\n- **Shorter timeout** for single-word commands (e.g. \"undo\", \"save\") where speed matters\n- **Longer timeout** for multi-word phrases or dictation where cutting off mid-sentence is costly\n- **Context-aware** — different timeouts in command mode vs dictation mode, or per-application\n\n### What we know works\n\nThe VAD timeout can be changed at runtime without restarting Talon:\n\n```python\nfrom talon import speech_system\nspeech_system.vad.set_timeout(0.15)  # faster\nspeech_system.vad.set_timeout(0.4)   # more patient\n```\n\nThis directly mutates the C struct (`speech_system.vad.config.timeout`) and takes effect immediately on the next audio frame.\n\n### Possible approaches\n\n1. **Mode-based**: Use Talon contexts to set different timeouts — e.g. `speech.timeout = 0.15` in command mode, `speech.timeout = 0.4` in dictation mode\n2. **Adaptive**: A Python module that calls `vad.set_timeout()` based on heuristics — recent phrase length, current mode, active tags\n3. **Post-phrase adjustment**: After each phrase, predict whether the next phrase is likely short or long and adjust accordingly\n4. **Manual voice toggle**: Commands like \"fast mode\" / \"patient mode\" that switch between presets\n\n### Key tradeoff\n\nLower timeout = faster command execution but risks cutting off multi-word phrases\nHigher timeout = more reliable phrase capture but everything feels slower\n\nThe sweet spot likely varies by usage pattern, which is why dynamic adjustment is interesting.","status":"open","priority":2,"issue_type":"task","owner":"trillium@trilliumsmith.com","created_at":"2026-02-19T12:05:12.507609431-08:00","created_by":"Trillium Smith","updated_at":"2026-02-19T12:06:21.532350368-08:00","labels":["internals","performance","speech","talon"]}
